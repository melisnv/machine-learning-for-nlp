{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158bb4e2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of this assignment is to create a basic program that provides an overview of basic evaluation metrics (in particular, precision, recall, f-score and a confusion matrix) from documents provided in the conll format. You will need to implement the calculations for precision, recall and f-score yourself (i.e. do not use an existing module that spits them out). Make sure that your code can handle the situation where there are no true positives for a specific class.\n",
    "\n",
    "This notebook provides functions for reading in conll structures with pandas and proposes a structure for calculating your evaluation metrics and producing the confusion matrix. Feel free to adjust the proposed structure if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6819beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# see tips & tricks on using defaultdict (remove when you do not use it)\n",
    "from collections import defaultdict, Counter\n",
    "# module for verifying output\n",
    "from nose.tools import assert_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c64523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotations(inputfile, annotationcolumn,column_name,delimiter='\\t'):\n",
    "    '''\n",
    "    This function extracts annotations represented in the conll format from a file\n",
    "    \n",
    "    :param inputfile: the path to the conll file\n",
    "    :param annotationcolumn: the name of the column in which the target annotation is provided\n",
    "    :param delimiter: optional parameter to overwrite the default delimiter (tab)\n",
    "    :type inputfile: string\n",
    "    :type annotationcolumn: string\n",
    "    :type delimiter: string\n",
    "    :returns: the annotations as a list\n",
    "    '''\n",
    "    #https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "    \n",
    "    conll_input = pd.read_csv(inputfile, sep=delimiter, on_bad_lines='skip',names=column_name)\n",
    "    annotations = conll_input[annotationcolumn].tolist()\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a40424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotations_mini(inputfile, annotationcolumn,delimiter='\\t'):\n",
    "    '''\n",
    "    This function extracts annotations represented in the conll format from a file\n",
    "    \n",
    "    :param inputfile: the path to the conll file\n",
    "    :param annotationcolumn: the name of the column in which the target annotation is provided\n",
    "    :param delimiter: optional parameter to overwrite the default delimiter (tab)\n",
    "    :type inputfile: string\n",
    "    :type annotationcolumn: string\n",
    "    :type delimiter: string\n",
    "    :returns: the annotations as a list\n",
    "    '''\n",
    "    #https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "    \n",
    "    conll_input = pd.read_csv(inputfile, sep=delimiter, on_bad_lines='skip')\n",
    "    annotations = conll_input[annotationcolumn].tolist()\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1237f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Computational',\n",
       " 'Lexicology',\n",
       " 'and',\n",
       " 'Terminology',\n",
       " 'Lab',\n",
       " 'headed',\n",
       " 'by',\n",
       " 'Piek',\n",
       " 'Vossen',\n",
       " 'offers',\n",
       " 'mutliple',\n",
       " 'courses',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_annotations_mini(\"datas/minigold.csv\",\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30fadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldannotations = extract_annotations_mini(\"datas/minigold.csv\",\"gold\")\n",
    "machineannotations = extract_annotations_mini(\"datas/miniout1.csv\",\"NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bca2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goldannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0784624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machineannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b261e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 10, 'B-ORG': 2, 'I-ORG': 2, 'B-PER': 1, 'I-PER': 1}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i in machineannotations:\n",
    "    results[i] = machineannotations.count(i)\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ff1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 8, 'B-ORG': 2, 'I-ORG': 3, 'B-PER': 1, 'I-PER': 1, 'B-MISC': 1}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i in goldannotations:\n",
    "    results[i] = goldannotations.count(i)\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a3ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_counts(goldannotations, machineannotations):\n",
    "    '''\n",
    "    This function compares the gold annotations to machine output\n",
    "    \n",
    "    :param goldannotations: the gold annotations\n",
    "    :param machineannotations: the output annotations of the system in question\n",
    "    :type goldannotations: the type of the object created in extract_annotations\n",
    "    :type machineannotations: the type of the object created in extract_annotations\n",
    "    \n",
    "    :returns: a countainer providing the counts for each predicted and gold class pair\n",
    "    '''\n",
    "    evaluation_counts = defaultdict(Counter)\n",
    "    \n",
    "    evaluation_counts['O']['O'] = 0\n",
    "    evaluation_counts['O']['B-ORG'] = 0\n",
    "    evaluation_counts['O']['I-ORG'] = 0\n",
    "    evaluation_counts['O']['B-PER'] = 0\n",
    "    evaluation_counts['O']['I-PER'] = 0\n",
    "    evaluation_counts['O']['B-MISC'] = 0\n",
    "\n",
    "    evaluation_counts['B-ORG']['O'] = 0\n",
    "    evaluation_counts['B-ORG']['B-ORG'] = 0\n",
    "    evaluation_counts['B-ORG']['I-ORG'] = 0\n",
    "    evaluation_counts['B-ORG']['B-PER'] = 0\n",
    "    evaluation_counts['B-ORG']['I-PER'] = 0\n",
    "    evaluation_counts['B-ORG']['B-MISC'] = 0\n",
    "\n",
    "    evaluation_counts['I-ORG']['O'] = 0\n",
    "    evaluation_counts['I-ORG']['B-ORG'] = 0\n",
    "    evaluation_counts['I-ORG']['I-ORG'] = 0\n",
    "    evaluation_counts['I-ORG']['B-PER'] = 0\n",
    "    evaluation_counts['I-ORG']['I-PER'] = 0\n",
    "    evaluation_counts['I-ORG']['B-MISC'] = 0\n",
    "\n",
    "    evaluation_counts['B-PER']['O'] = 0\n",
    "    evaluation_counts['B-PER']['B-ORG'] = 0\n",
    "    evaluation_counts['B-PER']['I-ORG'] = 0\n",
    "    evaluation_counts['B-PER']['B-PER'] = 0\n",
    "    evaluation_counts['B-PER']['I-PER'] = 0\n",
    "    evaluation_counts['B-PER']['B-MISC'] = 0\n",
    "\n",
    "    evaluation_counts['I-PER']['O'] = 0\n",
    "    evaluation_counts['I-PER']['B-ORG'] = 0\n",
    "    evaluation_counts['I-PER']['I-ORG'] = 0\n",
    "    evaluation_counts['I-PER']['B-PER'] = 0\n",
    "    evaluation_counts['I-PER']['I-PER'] = 0\n",
    "    evaluation_counts['I-PER']['B-MISC'] = 0\n",
    "\n",
    "    evaluation_counts['B-MISC']['O'] = 0\n",
    "    evaluation_counts['B-MISC']['B-ORG'] = 0\n",
    "    evaluation_counts['B-MISC']['I-ORG'] = 0\n",
    "    evaluation_counts['B-MISC']['B-PER'] = 0\n",
    "    evaluation_counts['B-MISC']['I-PER'] = 0\n",
    "    evaluation_counts['B-MISC']['B-MISC'] = 0\n",
    "\n",
    "    for gold_annotation, machine_annotation in zip(goldannotations, machineannotations):\n",
    "        evaluation_counts[gold_annotation][machine_annotation] += 1\n",
    "        \n",
    "    return evaluation_counts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc6e1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'O': Counter({'O': 8,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'B-ORG': Counter({'O': 0,\n",
       "                      'B-ORG': 2,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'I-ORG': Counter({'O': 1,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 2,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'B-PER': Counter({'O': 0,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 1,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'I-PER': Counter({'O': 0,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 1,\n",
       "                      'B-MISC': 0}),\n",
       "             'B-MISC': Counter({'O': 1,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0})})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_counts = obtain_counts(goldannotations,machineannotations)\n",
    "evaluation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "650d063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_confusion_matrix(evaluation_counts):\n",
    "    '''\n",
    "    Read in the evaluation counts and provide a confusion matrix for each class\n",
    "    \n",
    "    :param evaluation_counts: a container from which you can obtain the true positives, false positives and false negatives for each class\n",
    "    :type evaluation_counts: type of object returned by obtain_counts\n",
    "    \n",
    "    :prints out a confusion matrix\n",
    "    '''\n",
    "    \n",
    "    # TIP: provide_output_tables does something similar, but those tables are assuming one additional nested layer\n",
    "    # your solution can thus be a simpler version of the one provided in provide_output_tables below\n",
    "    \n",
    "    confusion_matrix = pd.DataFrame.from_dict({i: evaluation_counts[i] for i in evaluation_counts.keys()}, orient='index')\n",
    "    #confusion_matrix = confusion_matrix.reindex(sorted(confusion_matrix.columns), axis=1)\n",
    "    #confusion_matrix = confusion_matrix.reindex(sorted(confusion_matrix.columns), axis=0)\n",
    "    confusion_matrix = confusion_matrix.fillna(0)\n",
    "    #confusion_matrix = confusion_matrix.round(0).astype(int)\n",
    "\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d34353b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-ORG</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>B-PER</th>\n",
       "      <th>I-PER</th>\n",
       "      <th>B-MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PER</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        O  B-ORG  I-ORG  B-PER  I-PER  B-MISC\n",
       "O       8      0      0      0      0       0\n",
       "B-ORG   0      2      0      0      0       0\n",
       "I-ORG   1      0      2      0      0       0\n",
       "B-PER   0      0      0      1      0       0\n",
       "I-PER   0      0      0      0      1       0\n",
       "B-MISC  1      0      0      0      0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = provide_confusion_matrix(evaluation_counts)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac5ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall_fscore(evaluation_counts):\n",
    "    '''\n",
    "    Calculate precision recall and fscore for each class and return them in a dictionary\n",
    "    \n",
    "    :param calculate_true_false: a tuple from which you can obtain the true positives, false positives and false negatives for each class\n",
    "    :type calculate_true_false: type of object returned by obtain_counts\n",
    "    \n",
    "    :returns the precision, recall and f-score of each class in a container\n",
    "    '''\n",
    "        \n",
    "    # recall = TP / (TP+FN)\n",
    "    # precision = TP / (TP+FP)\n",
    "    # f1_score = (2*precision*recall) / (precision+recall)\n",
    "    # accuracy =  (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    conf_matrix = provide_confusion_matrix(evaluation_counts)\n",
    "    \n",
    "    sum_of_rows = conf_matrix.sum(axis=1)\n",
    "    sum_of_columns = conf_matrix.sum(axis=0)\n",
    "    #total_sum = conf_matrix.sum()\n",
    "    \n",
    "    # initialize the lists\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    f1_score = []\n",
    "    \n",
    "    for i in range(len(conf_matrix)):\n",
    "        precision.append((conf_matrix.iloc[i, i] / sum_of_columns[i]))\n",
    "        recall.append(conf_matrix.iloc[i, i] / sum_of_rows[i])\n",
    "        f1_score.append((2* (precision[i] * recall[i])) / (precision[i] + recall[i]))\n",
    "\n",
    "    return precision,recall,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00789891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ORG\tB-PER\tI-ORG\tI-PER\tO\n",
      "[0.8, 1.0, 1.0, 1.0, 1.0, nan]\n",
      "[1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]\n",
      "[0.888888888888889, 1.0, 0.8, 1.0, 1.0, nan]\n"
     ]
    }
   ],
   "source": [
    "precision,recall,f1_score = calculate_precision_recall_fscore(evaluation_counts)\n",
    "print(\"B-ORG\tB-PER\tI-ORG\tI-PER\tO\")\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e06e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carry_out_evaluation(gold_annotations, systemfile, systemcolumn, delimiter='\\t'):\n",
    "    '''\n",
    "    Carries out the evaluation process (from input file to calculating relevant scores)\n",
    "    \n",
    "    :param gold_annotations: list of gold annotations\n",
    "    :param systemfile: path to file with system output\n",
    "    :param systemcolumn: indication of column with relevant information\n",
    "    :param delimiter: specification of formatting of file (default delimiter set to '\\t')\n",
    "    \n",
    "    returns evaluation information for this specific system\n",
    "    '''\n",
    "    system_annotations = extract_annotations_mini(systemfile, systemcolumn, delimiter)\n",
    "    evaluation_counts = obtain_counts(gold_annotations, system_annotations)\n",
    "    provide_confusion_matrix(evaluation_counts)\n",
    "    evaluation_outcome = calculate_precision_recall_fscore(evaluation_counts)\n",
    "    \n",
    "    return evaluation_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac8b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_output_tables(evaluations):\n",
    "    '''\n",
    "    Create tables based on the evaluation of various systems\n",
    "    \n",
    "    :param evaluations: the outcome of evaluating one or more systems\n",
    "    '''\n",
    "    #https:stackoverflow.com/questions/13575090/construct-pandas-dataframe-from-items-in-nested-dictionary\n",
    "    evaluations_pddf = pd.DataFrame.from_dict({(i,j): evaluations[i][j]\n",
    "                                              for i in evaluations.keys()\n",
    "                                              for j in evaluations[i].keys()},\n",
    "                                             orient='index')\n",
    "    print(evaluations_pddf)\n",
    "    print(evaluations_pddf.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e55b8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluations(goldfile, goldcolumn, systems):\n",
    "    '''\n",
    "    Carry out standard evaluation for one or more system outputs\n",
    "    \n",
    "    :param goldfile: path to file with goldstandard\n",
    "    :param goldcolumn: indicator of column in gold file where gold labels can be found\n",
    "    :param systems: required information to find and process system output\n",
    "    :type goldfile: string\n",
    "    :type goldcolumn: integer\n",
    "    :type systems: list (providing file name, information on tab with system output and system name for each element)\n",
    "    \n",
    "    :returns the evaluations for all systems\n",
    "    '''\n",
    "    evaluations = {}\n",
    "    #not specifying delimiters here, since it corresponds to the default ('\\t')\n",
    "    gold_annotations = extract_annotations_mini(goldfile, goldcolumn)\n",
    "    for system in systems:\n",
    "        sys_evaluation = carry_out_evaluation(gold_annotations, system[0], system[1])\n",
    "        evaluations[system[2]] = sys_evaluation\n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79aaa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_evaluation_value(system, class_label, value_name, evaluations):\n",
    "    '''\n",
    "    Return the outcome of a specific value of the evaluation\n",
    "    \n",
    "    :param system: the name of the system\n",
    "    :param class_label: the name of the class for which the value should be returned\n",
    "    :param value_name: the name of the score that is returned\n",
    "    :param evaluations: the overview of evaluations\n",
    "    \n",
    "    :returns the requested value\n",
    "    '''\n",
    "    return evaluations[system][class_label][value_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a1095b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_information(system_information):\n",
    "    '''\n",
    "    Takes system information in the form that it is passed on through sys.argv or via a settingsfile\n",
    "    and returns a list of elements specifying all the needed information on each system output file to carry out the evaluation.\n",
    "    \n",
    "    :param system_information is the input as from a commandline or an input file\n",
    "    '''\n",
    "    # https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "    systems_list = [system_information[i:i + 3] for i in range(0, len(system_information), 3)]\n",
    "    return systems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "878a04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(label_gold, label_model):\n",
    "    eval_counts = obtain_counts(label_gold, label_model)\n",
    "    confusion_matrix = provide_confusion_matrix(eval_counts)\n",
    "    precision,recall,f1_score = calculate_precision_recall_fscore(eval_counts)\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1a59211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(my_args=None):\n",
    "    '''\n",
    "    A main function. This does not make sense for a notebook, but it is here as an example.\n",
    "    sys.argv is a very lightweight way of passing arguments from the commandline to a script.\n",
    "    '''\n",
    "    \n",
    "    if my_args is None:\n",
    "        my_args = sys.argv\n",
    "    \n",
    "    system_info = create_system_information(my_args[2:])\n",
    "    evaluations = run_evaluations(my_args[0], my_args[1], system_info)\n",
    "    provide_output_tables(evaluations)\n",
    "    check_eval = identify_evaluation_value('system1', 'O', 'f-score', evaluations)\n",
    "    #if it does not work correctly, this assert statement will indicate that\n",
    "    assert_equal(\"%.3f\" % check_eval,\"0.889\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c838ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_args = ['datas/minigold.csv','gold','datas/miniout1.csv','NER','system1']\n",
    "#main(my_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adb8a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.8, 1.0, 1.0, 1.0, 1.0, nan], [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0], [0.888888888888889, 1.0, 0.8, 1.0, 1.0, nan])\n"
     ]
    }
   ],
   "source": [
    "evaluation_outcome = carry_out_evaluation(gold_annotations=goldannotations,systemfile=\"datas/miniout1.csv\",systemcolumn=\"NER\")\n",
    "print(evaluation_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b86274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.8, nan, 0.5, nan, 0.5, nan], [1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0], [0.888888888888889, nan, 0.5714285714285715, nan, 0.6666666666666666, nan])\n"
     ]
    }
   ],
   "source": [
    "evaluation_outcome = carry_out_evaluation(gold_annotations=goldannotations,systemfile=\"datas/miniout2.csv\",\n",
    "                                          systemcolumn=\"NER\")\n",
    "print(evaluation_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11215738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'O': Counter({'O': 8,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'B-ORG': Counter({'O': 0,\n",
       "                      'B-ORG': 2,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'I-ORG': Counter({'O': 1,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 2,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'B-PER': Counter({'O': 0,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 1,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0}),\n",
       "             'I-PER': Counter({'O': 0,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 1,\n",
       "                      'B-MISC': 0}),\n",
       "             'B-MISC': Counter({'O': 1,\n",
       "                      'B-ORG': 0,\n",
       "                      'I-ORG': 0,\n",
       "                      'B-PER': 0,\n",
       "                      'I-PER': 0,\n",
       "                      'B-MISC': 0})})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccc375b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-ORG</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>B-PER</th>\n",
       "      <th>I-PER</th>\n",
       "      <th>B-MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PER</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        O  B-ORG  I-ORG  B-PER  I-PER  B-MISC\n",
       "O       8      0      0      0      0       0\n",
       "B-ORG   0      2      0      0      0       0\n",
       "I-ORG   1      0      2      0      0       0\n",
       "B-PER   0      0      0      1      0       0\n",
       "I-PER   0      0      0      0      1       0\n",
       "B-MISC  1      0      0      0      0       0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = provide_confusion_matrix(evaluation_counts)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe92a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ORG\tB-PER\tI-ORG\tI-PER\tO\n",
      "[0.8, 1.0, 1.0, 1.0, 1.0, nan]\n",
      "[1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]\n",
      "[0.888888888888889, 1.0, 0.8, 1.0, 1.0, nan]\n"
     ]
    }
   ],
   "source": [
    "precision,recall,f1_score = calculate_precision_recall_fscore(evaluation_counts)\n",
    "print(\"B-ORG\tB-PER\tI-ORG\tI-PER\tO\")\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34f177",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "## Linear Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0483139",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldannotations = extract_annotations(\"outputfile\",\"gold\",[\"token\",\"tag1\",\"tag2\",\"gold\",\"predicted\"])\n",
    "machineannotations = extract_annotations(\"outputfile\",\"predicted\",[\"token\",\"tag1\",\"tag2\",\"gold\",\"predicted\"])\n",
    "#machineannotations\n",
    "#goldannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb355bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'O': Counter({'O': 167258,\n",
       "                      'B-ORG': 21,\n",
       "                      'I-ORG': 38,\n",
       "                      'B-PER': 3,\n",
       "                      'I-PER': 6,\n",
       "                      'B-MISC': 15,\n",
       "                      nan: 2178,\n",
       "                      'I-MISC': 37,\n",
       "                      'B-LOC': 18,\n",
       "                      'I-LOC': 4}),\n",
       "             'B-ORG': Counter({'O': 1394,\n",
       "                      'B-ORG': 4191,\n",
       "                      'I-ORG': 133,\n",
       "                      'B-PER': 22,\n",
       "                      'I-PER': 21,\n",
       "                      'B-MISC': 138,\n",
       "                      'B-LOC': 385,\n",
       "                      'I-LOC': 32,\n",
       "                      'I-MISC': 5}),\n",
       "             'I-ORG': Counter({'O': 1494,\n",
       "                      'B-ORG': 130,\n",
       "                      'I-ORG': 1703,\n",
       "                      'B-PER': 23,\n",
       "                      'I-PER': 15,\n",
       "                      'B-MISC': 38,\n",
       "                      'B-LOC': 151,\n",
       "                      'I-LOC': 138,\n",
       "                      'I-MISC': 12}),\n",
       "             'B-PER': Counter({'O': 1915,\n",
       "                      'B-ORG': 25,\n",
       "                      'I-ORG': 7,\n",
       "                      'B-PER': 4347,\n",
       "                      'I-PER': 290,\n",
       "                      'B-MISC': 2,\n",
       "                      'B-LOC': 10,\n",
       "                      'I-LOC': 4}),\n",
       "             'I-PER': Counter({'O': 2165,\n",
       "                      'B-ORG': 34,\n",
       "                      'I-ORG': 10,\n",
       "                      'B-PER': 544,\n",
       "                      'I-PER': 1730,\n",
       "                      'B-MISC': 3,\n",
       "                      'I-MISC': 6,\n",
       "                      'B-LOC': 33,\n",
       "                      'I-LOC': 3}),\n",
       "             'B-MISC': Counter({'O': 653,\n",
       "                      'B-ORG': 70,\n",
       "                      'I-ORG': 12,\n",
       "                      'B-PER': 19,\n",
       "                      'I-PER': 1,\n",
       "                      'B-MISC': 2478,\n",
       "                      'B-LOC': 144,\n",
       "                      'I-MISC': 56,\n",
       "                      'I-LOC': 5}),\n",
       "             'B-LOC': Counter({'B-LOC': 5578,\n",
       "                      'B-ORG': 329,\n",
       "                      'O': 1101,\n",
       "                      'B-MISC': 35,\n",
       "                      'I-PER': 7,\n",
       "                      'I-ORG': 45,\n",
       "                      'I-LOC': 32,\n",
       "                      'B-PER': 11,\n",
       "                      'I-MISC': 2}),\n",
       "             'I-MISC': Counter({'O': 477,\n",
       "                      'I-MISC': 515,\n",
       "                      'B-MISC': 87,\n",
       "                      'I-PER': 8,\n",
       "                      'I-LOC': 10,\n",
       "                      'B-ORG': 19,\n",
       "                      'B-LOC': 11,\n",
       "                      'I-ORG': 27,\n",
       "                      'B-PER': 1}),\n",
       "             'I-LOC': Counter({'O': 323,\n",
       "                      'I-LOC': 672,\n",
       "                      'B-ORG': 8,\n",
       "                      'B-MISC': 5,\n",
       "                      'B-LOC': 48,\n",
       "                      'I-ORG': 71,\n",
       "                      'I-PER': 13,\n",
       "                      'B-PER': 14,\n",
       "                      'I-MISC': 3})})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_counts = obtain_counts(goldannotations,machineannotations)\n",
    "evaluation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba970ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-ORG</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>B-PER</th>\n",
       "      <th>I-PER</th>\n",
       "      <th>B-MISC</th>\n",
       "      <th>NaN</th>\n",
       "      <th>I-MISC</th>\n",
       "      <th>B-LOC</th>\n",
       "      <th>I-LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>167258</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>1394</td>\n",
       "      <td>4191</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>385</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>1494</td>\n",
       "      <td>130</td>\n",
       "      <td>1703</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>151</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PER</th>\n",
       "      <td>1915</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>4347</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>2165</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>544</td>\n",
       "      <td>1730</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>653</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>1101</td>\n",
       "      <td>329</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5578</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>477</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>323</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             O  B-ORG  I-ORG  B-PER  I-PER  B-MISC     NaN  I-MISC  B-LOC  \\\n",
       "O       167258     21     38      3      6      15  2178.0    37.0     18   \n",
       "B-ORG     1394   4191    133     22     21     138     0.0     5.0    385   \n",
       "I-ORG     1494    130   1703     23     15      38     0.0    12.0    151   \n",
       "B-PER     1915     25      7   4347    290       2     0.0     0.0     10   \n",
       "I-PER     2165     34     10    544   1730       3     0.0     6.0     33   \n",
       "B-MISC     653     70     12     19      1    2478     0.0    56.0    144   \n",
       "B-LOC     1101    329     45     11      7      35     0.0     2.0   5578   \n",
       "I-MISC     477     19     27      1      8      87     0.0   515.0     11   \n",
       "I-LOC      323      8     71     14     13       5     0.0     3.0     48   \n",
       "\n",
       "        I-LOC  \n",
       "O           4  \n",
       "B-ORG      32  \n",
       "I-ORG     138  \n",
       "B-PER       4  \n",
       "I-PER       3  \n",
       "B-MISC      5  \n",
       "B-LOC      32  \n",
       "I-MISC     10  \n",
       "I-LOC     672  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = provide_confusion_matrix(evaluation_counts)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8f1f153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\tB-ORG\tI-ORG\tB-PER\tI-PER\tB-MISC\tNaN\tI-MISC\tB-LOC\tI-LOC\n",
      "[0.9461364407738432, 0.8682411435674332, 0.832355816226784, 0.8721910112359551, 0.8273553323768532, 0.8846840414137808, 0.0, 0.809748427672956, 0.007525870178739417]\n",
      "[0.9863189800563752, 0.6630280018984338, 0.4597732181425486, 0.6586363636363637, 0.3820671378091873, 0.7207678883071553, 0.0, 0.4458874458874459, 0.04148660328435609]\n",
      "[0.965809942314022, 0.7518837459634016, 0.5923478260869566, 0.7505179558011049, 0.522737573651609, 0.7943580702035582, nan, 0.5750977107761027, 0.012740544127405442]\n"
     ]
    }
   ],
   "source": [
    "precision,recall,f1_score = calculate_precision_recall_fscore(evaluation_counts)\n",
    "print(\"O\tB-ORG\tI-ORG\tB-PER\tI-PER\tB-MISC\tNaN\tI-MISC\tB-LOC\tI-LOC\")\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22f5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
